---
description: >-
  You write software that produces reliable data and insights. Less modeling
  theory, more engineering that enables analysis.
---

# 1.5 Data-Focused SWE

### **What to emphasize**

* Logging, event definitions, ETL, quality checks
* Simple analytics and dashboards that drive decisions
* Reproducibility and ownership of data artifacts

### Copy-paste prompts

#### **Role‑specific SWITCHER**

```prompt
SWITCH ROLE → Data‑adjacent SWE
Priority: instrumenting events, building ETL, and exposing trustworthy metrics. Use JD vocabulary for logging, dashboards, and data quality.
```

### **Core tailor prompt**

```prompt
Produce 2–3 Data‑adjacent SWE bullets aligned to the JD:
- Events or logs added and where they land.
- ETL or reporting tables built.
- One metric that drove a decision (DAU, conversion, latency, cost, accuracy).

JD:
[Paste]

Experience:
[Paste role or project]
```

#### **Role micro‑prompts**

* “Add one reproducibility proof such as a data dictionary or versioned query.”
* “Add one decision or action the metrics enabled.”

### Fix weak bullets for this role

```prompt
Ask me:
1) Events captured and definitions; where they are logged.
2) ETL cadence and failure handling; schema of reporting tables.
3) Dashboards or reports consumed by whom; example decisions influenced.
4) Data checks: nulls, ranges, schema versioning, backfills.
5) Storage and cost considerations if any.
Then write 2–3 bullets with one data outcome per bullet.
```

### Examples

### Short patterns you can model

* Instrumented signup and content actions, built a daily SQL job to compute DAU and first‑post conversion, and used the trend to re‑prioritize onboarding tasks during sprints.\
  TODO: add DAU and conversion values.
* Created materialized views for cohort retention and latency percentiles, documented definitions in a data dictionary, and reduced dashboard query time.\
  TODO: add percent speedup or refresh interval.

### **Before→After examples**

#### _Before_

* Tracked engagement in the app.

#### _After_

* Instrumented signup, post, comment, and like events with timestamps and user IDs, built a daily SQL job to compute DAU and first‑post conversion, and used the trend to prioritize onboarding fixes in the next sprint.\
  &#xNAN;_&#x54;ODO: add DAU and conversion values._

#### _Before_

* Built analytics dashboards.

#### _After_

* Created reporting tables for cohort retention and latency percentiles, documented definitions in a data dictionary, and cut dashboard query time by moving heavy joins into materialized views.\
  &#xNAN;_&#x54;ODO: add percent speedup or cache interval._

### Quick checklist

* Include at least one event or log you instrumented
* Show an ETL/reporting pipeline and its cadence
* Add one metric tied to a decision (DAU, conversion, latency, etc.)
* Mention one reproducibility proof (data dictionary, versioning)
* One line, verb first, correct tense
