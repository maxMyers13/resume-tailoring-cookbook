---
description: >-
  You own schema design, data quality, and query performance. Prove it with
  numbers.
---

# 1.3 Database SWE

### **What to emphasize**

* Relational modeling, constraints, indexing, migrations
* ETL or pipelines, data validation, reproducibility
* Query performance outcomes and correctness at scale

### Copy-Paste Prompts

#### **Role‑specific SWITCHER**

{% code overflow="wrap" %}
```prompt
SWITCH ROLE → Backend Database
Priority: schema decisions, constraints, indexes, and measurable query speedups. Use SQL, migrations, indexing, and data quality language the JD expects.
```
{% endcode %}

### Core Tailor Prompt:

```prompt
Produce 2–3 Backend Database bullets aligned to the JD:
- Tables and relationships you owned.
- Constraints and indexes that matter and which queries they sped up.
- One measurable query or ETL outcome (before vs after).

JD:
[Paste]

Experience:
[Paste role or project]
```

### Role micro-prompts

* “Add one EXPLAIN or index-impact fact without over-explaining.”
* “If you used an ORM, add the exact change that fixed an N+1 or a slow join.”

**Fix Weak Bullets for this role**

```prompt
Ask me:
1) Tables, key relationships, and constraints used.
2) Indexes added and which queries they speed up.
3) ETL steps, validation checks, and failure handling.
4) Query performance before vs after; sample sizes.
5) Data governance: access, roles, sensitive fields masked or not.
Then write 2–3 bullets with concrete DB outcomes.
```

### Examples

**Relevant samples from Paul + Ismail**

* **Paul**: Data pipeline that removed rule bloat and improved model training time; fraud detection feature engineering; Next.js booking system with Prisma and PostgreSQL.
* **Ismail**: Projects with PostgreSQL and SQLite backing search and auth; data extraction and storage choices explained.

#### Short patterns you can model

* Modeled a bookings schema in PostgreSQL with foreign keys and unique constraints, added composite indexes for top search paths, and reduced average availability query time under load.\
  TODO: add before vs after timings and traffic volume.
* Consolidated many hand‑written rules into a feature pipeline with Pandas, validated inputs with schema checks, and shortened model training cycles to enable faster iteration.\
  TODO: add rows processed and a concrete percent.

### **Before→After examples**

#### _Before_

* Built a fraud model with Python and Pandas.

#### _After_

* Consolidated 12,000 plus legacy rules into a Pandas feature pipeline, validated inputs with schema checks, and cut model training time by 30 percent on sampled datasets, enabling faster iteration on fraud thresholds.\
  &#xNAN;_&#x54;ODO: add rows processed and hardware context._

#### _Before_

* Created booking database.

#### _After_

* Modeled a PostgreSQL schema for bookings, drivers, and trips with foreign keys and unique constraints, added composite indexes for the top two search paths, and reduced average query time on availability lookups.\
  &#xNAN;_&#x54;ODO: add query timing before vs after._

### Quick checklist

* Include 1–2 schema details (tables, constraints, relationships)
* Mention one index or query optimization
* Show one measurable outcome (timing, rows, load handled)
* Add one data quality or validation detail
* One line, verb first, correct tense

